\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[twocolumn]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\date{}

\begin{document}

\hypertarget{linear-independece}{%
\section{Linear independece}\label{linear-independece}}

A system of vectors is linearly independent \(\Leftrightarrow\) (some
linear combination of the vectors is equal to the zero vector only has
trivail solutions

\[\sum_{i=1}^n a_i \alpha_i = \theta \Leftrightarrow \{ \alpha\}_1 ^n = 0\]

\hypertarget{basis}{%
\section{Basis}\label{basis}}

Basis :

\begin{itemize}
\tightlist
\item
  let v be a vector space over a field \textbf{F}
\item
  A system of vectors is a basis of v if

  \begin{itemize}
  \tightlist
  \item
    it is linearly independent
  \item
    the span of the vectors is v (that is every vector a from v can be
    written as a linear combination of those vectors\footnote{The
      coefficents called cordinates can be determined uniquely})
  \end{itemize}
\end{itemize}

\textbf{Let S be a finite subset of V whcih spans the whole space. Then
there is a basis of V contianed in S.}

\begin{quote}
Proof

\begin{quote}
It suffice to choose a linearly indepent system

\(a = \{ a_1 \dots a_n \} \subset S \wedge S \subset <a>\) Becouse if

\(<a_1 \dots a_n> = <<a_1 \dots a_n>> \subset <S>\)

If \(<a1> \in S\) , we are done

Otherwise we can pick \(a_3\) from \(S-a1 - a2 \wedge \in a_3 |S\) we
obtain the required system
\end{quote}
\end{quote}

\begin{itemize}
\tightlist
\item
  A vector space v is called finite dimensional if there is a finite
  subset of vectors in v which spans the whole of v

  \begin{itemize}
  \tightlist
  \item
    \textbf{corollory} every finite dimensional space vector space has a
    basis
  \end{itemize}
\end{itemize}

\hypertarget{all-bases-of-a-finite-vector-space-have-the-same-number-of-vectors}{%
\subsection[All bases of a finite vector space have the same number of
vectors]{\texorpdfstring{All bases of a finite vector space have the
same number of vectors\footnote{This is the main result about vector
  spaces}}{All bases of a finite vector space have the same number of vectors}}\label{all-bases-of-a-finite-vector-space-have-the-same-number-of-vectors}}

\hypertarget{main-result}{%
\subsubsection{Main result}\label{main-result}}

\textbf{Theorem} All basis of a finite dimensional vector space have he
same number of vectors.

\textbf{Proof}

\begin{quote}
Let A and B be two basis of V. We need to show that they have the same
cardinality and since B is linearly independent and the span of b is the
whole space \textbf{(2 systems lemma)}

\(|A| \geq |B| \wedge |B| \geq |A|\)
\end{quote}

\hypertarget{systems-lemma}{%
\subsubsection{2 systems lemma}\label{systems-lemma}}

\begin{itemize}
\tightlist
\item
  Let \(A = \{a_1 \dots a_n\} \quad B = \{b_1 \cdots b_m\}\) be 2
  systems of vectors in a vector space

  \begin{itemize}
  \tightlist
  \item
    Suppose B is linearly independent and \(B \subset <A>\)
  \item
    Then n is greater than or equel to m
  \end{itemize}
\end{itemize}

\textbf{Proof}

\begin{quote}
\textbf{Assume on the contrary that \(n < m\)}

\begin{itemize}
\tightlist
\item
  Let \(A_1 = \left[ b_1, A \right]\) be the system A and adding the
  vector b1 from the left

  \begin{itemize}
  \tightlist
  \item
    A1 is linearly dependent \textbf{(\(b_1 \in <A>\))}
  \end{itemize}
\item
  Let C1 donate the system obtained by removing any vector which is a
  linear combination of the preceading vectors.
\item
  This vector cannot be b1 \textbf{(B is linearly independent)}
\item
  \(|C1| = n\)
\item
  \(<c1> =<a>\)
\item
  Let A\_2 donate the system obtained from C1 obtained by adding the
  vector b2 from the left. A\_2 is linearly dependent becouse b2 belongs
  to the span of A and consiquenly C1
\item
  Let C2 donae the system obtained from A2 by removing any vector whcih
  is a linear combination of the preceading vectors.
\item
  This vector cannot be b2 nor b1 \textbf{(becouse B is linearly
  independent)}
\item
  \textbar{}C2\textbar{} = n = Continue in this process
\item
  In n steps we obtain the system Cn = \{b1 .. bn\} = 
\item
  Contradiction But than \(b_{n+1}\) belongs to the span of a
  contradiction \textbf{(B is linearly independent)}\footnote{Shouldn't
    this be a proof by induction?}
\end{itemize}
\end{quote}

\begin{description}
\item[Dimension of a vector space]
\end{description}

\begin{itemize}
\tightlist
\item
  Let V be a finite dimensional vector space
\item
  Dim of V is the number of vectors in a basis of V
\end{itemize}

\hypertarget{examples}{%
\subsubsection{Examples}\label{examples}}

\hypertarget{mathbbfn}{%
\paragraph{\texorpdfstring{\(\mathbb{F}^n\)}{\textbackslash{}mathbb\{F\}\^{}n}}\label{mathbbfn}}

Let E be a system/set\footnote{order doesn't matter} of vectors
\(\{e_i\}_{i=1}^n\)

\begin{quote}
\textbf{Where}

\(e_i\) is a vector whose ith coordinate is 1 with all other coordinates
0
\end{quote}

E is a basis of \(\mathbb{F}^n\).

\begin{quote}
\textbf{Proof}
\end{quote}

\begin{itemize}
\tightlist
\item
  E is linearly idependent \textbf{(No scalar multiple or sum of 0's is
  1)}
\item
  \(<E> = \mathbb{F}^n\)

  \begin{itemize}
  \tightlist
  \item
    \(\forall x \in F^n\) \(x = (x1, ... ,xn)\)
  \item
    \(\Rightarrow(x_1e_1, \cdots, x_ne_n) = x\)
  \end{itemize}
\end{itemize}

\hypertarget{second-example}{%
\subsubsection{Second example}\label{second-example}}

\begin{itemize}
\tightlist
\item
  The coordinate space \(F_n[x]\) polinomials with a degree not
  exceeding n
\item
  The stanadard bases is \$\{1, x\^{}2 ..x\^{}n\} the dimensions of this
  vector space in n+1
\end{itemize}

\hypertarget{third-example}{%
\subsubsection{Third example}\label{third-example}}

The space of 2 by 2 matrixes Standard basis is ones and zeros

\hypertarget{cordinates-and-isomorphs}{%
\section{Cordinates and isomorphs}\label{cordinates-and-isomorphs}}

Cordinates :

A set of coefficients that when multiplied by a basis result in a
specific vector x

Isomorph :

Two vector spaces are isoporphs if there is a bijection between them
which presevers some important porperties. Scalar multiplication and
addition.

\hypertarget{finding-isomorph-transformation}{%
\subsection{Finding isomorph
transformation}\label{finding-isomorph-transformation}}

If V is a vector space over a field \(\mathbb{F}\) and S is a basis of V
\(\{s_1, \dots s_n\}\).

Then the coordinates of v \(v_{[s]} = \{\alpha_i\}_{i=1}^n\) are the
system of coeeficients which mulitplied by S are equel to v, and is
called the coordinate vector.

\begin{itemize}
\tightlist
\item
  If we have a new bases \(S'= \{s'_1 \dots s'_n\}\)

  \begin{itemize}
  \tightlist
  \item
    Then we have new cordinates \([x]_{s'} = \{\beta_j\}_{j=1}^n\)
  \end{itemize}
\item
  \textbf{To find the isomorph transormation}
\item
  \(x = \sum_{j=1}^n \beta_j s'_j\)
\item
  \(s'_j = \sum_{i=1}^n \gamma_{ji} s_i\)

  \begin{itemize}
  \tightlist
  \item
    Express the vecotrs in the new basis in terms of the old basis
  \end{itemize}
\item
  \(= \sum_{j=1}^n \beta_j \left(\sum_{i=1}^n \gamma_{ji} s_i)\right)\)
\item
  \(= \sum_{i=1}^n s_i \left(\sum_{j=1}^n \beta_j \gamma_{ji} \right)\)
\item
  \(= \sum_{i=1}^n \begin{pmatrix} s_{1i} \\ \vdots \\ s_{ji} \end{pmatrix}\left( \sum_{j=1}^n \gamma_{ji} \beta_i \right)\)
\item
  \(= \sum_{i=1}^n \begin{pmatrix} s_{1i} \left( \sum_{j=1}^n \gamma_{ji} \beta_i \right)\\ \vdots \\ s_{ji} \left( \sum_{j=1}^n \gamma_{ji} \beta_i \right)\end{pmatrix}\)
\item
  \(= \sum_{i=1}^n \begin{pmatrix} s_{1i} ( \gamma_{1i} \dots \gamma_{ji} )\\ \vdots \\ s_{ji} (\gamma_{1i} \dots \gamma_{ji})\end{pmatrix} \beta\)
\item
  \(= \begin{pmatrix} \sum_{i=1}^n s_{1i} \gamma_{1i} \dots \sum_{i=1}^n \gamma_{ji} \gamma_{ji} )\\ \vdots \\ \sum_{i=1}^n s_{ji} \gamma_{1i} \dots \sum_{i=1}^n\gamma_{ji})\end{pmatrix} \beta\)
\item
  \(= \Gamma S \beta\)
\item
  \textbf{Possibly with a tranformation} \textbf{Check}
\item
  Write as the product of matrix gamma and vector beta
\item
  the matirx to the poweroff of minux one will do the oposite prosseses.
\end{itemize}

\hypertarget{examples-for-computing-the-transition-matix}{%
\subsection{Examples for computing the transition
matix}\label{examples-for-computing-the-transition-matix}}

\begin{itemize}
\item
\item
  Let S be the standard basis of the plane \(\mathbb{R}^2\)
\item
  Let S' be the basis of R\^{}2 obtained by rotating the plane
  countercloakwise above the origin through an angle 5
\item
  Find The transition matrix from the old matrix to the new basis
\item
\item
  Draw a diagram
\item
  form Traingle to new basis vectors
\item
  Write the new basis as some some of the old basis
\item
  e1' = cos theta e1 + sin theta e2
\item
  e2' = -sin theta e1 + cos phi e2
\item
  Form matrix by taking the transpose of
\item
  Suppose we are in \(F_u[x]\) S is old(standard) basis s' is new basis
  1 x+a (x+a)\^{}2 Find the tranformation vector Transition matrix will
  be upper triangles of with columns nC0 down to nCn
\item
  Third examples
\item
  Solve the matirx equation
\item
  Write A \textbar{} B and find reduced row echelon form The result on
  the the B side is the elementary matirx. where A and b are old and new
  written with matrixes as collumns
\end{itemize}

\hypertarget{proof-method-works}{%
\subsubsection{Proof method works}\label{proof-method-works}}

The justification of the elementary row operations method is based on
the following simple fact.

\begin{quote}
\textbf{lemma}

let A be an \(m \times n\) matrix and let b be the matrix obetained from
A from an elemantary row operation. Than B is \(F \cdot A\) where F is
the matrix obtained from the identity matirx of the identity matrix of
order m by the same elemtary row operation.

\textbf{Proof} \(F = I\) \(F_1\) can be obtained by one elemtary
operation on F \(F A\) the matrix a obtained by the same elementry row
opperation
\end{quote}

Suppose we have n by 2nd matrix \((A |B)\) and we apply operations
\(\tau_1\) to \(tau_n\) we claim that \(C A^-1= B\) let \(F_1\) to
\(F_k\) be the matirxes obtained from the elemantary matrix obtained by
the elematary row operations. than by the elemantary row operationsi

lemma \(F_k\) to \(F_1\cdots F1A=E\)

\begin{itemize}
\tightlist
\item
  \(F_k \dots F_1 B = C\)
\item
  \(F_k \to F_1 == A^{-1}\)
\item
  \(C = A^{-1}B\)
\end{itemize}

Non Standard Exersize not in exam suppose we are given a rectanglur
matrix whos entries are integers and we are alloed to multiply any row
or any colom by -1. Proove by using finitily many such operations we can
reduce our matrix to a matrix such that whenever we take a row or a
colum the sum of elements will be be nonnegative. Produce an algorithm
to do this.

\hypertarget{subspaces-and-direct-sums}{%
\section{Subspaces and direct sums}\label{subspaces-and-direct-sums}}

Let \(v\) be a vector space over field f.

w is a subspace of v if

\begin{itemize}
\tightlist
\item
  w is closed under vector addition.
\item
  w is closed under scaler multiplication
\item
  every subspace is a vector space
\end{itemize}

Every vector space has at least 2 trivial subspace trvial subspaces and
the whole space V. All other subspaces are called non trivial or proper

Examples

\begin{itemize}
\tightlist
\item
  \(\mathbb{R}^3\)
\item
  Lines and planes through the origin
\item
  The space of polinomiels of degree not exceeding n is a subspac of all
  polinomies
\item
  The set \(C[0,1]\) of all contious real valued functions definied on
  the unit interval is a subspace of all functions on the unit interval
  \}*\(<S>\) is the smallest subspace containing S
\item
  A \(m \times n\) matrix over a field F and consider \(Ax=O\)

  \begin{itemize}
  \tightlist
  \item
    the solutions of this equation form a subspace of \(F^n\)
  \end{itemize}
\end{itemize}

\hypertarget{execizes}{%
\subsection{Execizes}\label{execizes}}

\begin{itemize}
\tightlist
\item
  Proove that for any subspace \(Wi \in V i\in I\) the intersection of
  subspaces is always a subsapce.

  \begin{itemize}
  \tightlist
  \item
    let x and y be any vectors from that interesection
  \item
    each Wi is a subspace than for each I x + y belongs to Wi
  \item
    Assuming that V is finaite dimensionsal proove that for all
    subspaces \(W \subset V\) the dimension of \(W \geq 0\) and is less
    than or equal to the dimension of V. Furthur more the dimension of w
    is zero if and only if w is the zero vector
  \end{itemize}
\item
  \(0 \leq W \leq dimV\)
\item
  pick a basis of W and extend it to a bases of V
\end{itemize}

\hypertarget{direct-sum}{%
\section{Direct Sum}\label{direct-sum}}

There are teo operations which are direct sums and are anologious. The
cartisian cross with a new F and the addition of a vector not in the
existing basis.

\begin{itemize}
\tightlist
\item
  Proove that
  \(\forall W_i \subset V \exists W_1 + \cdots + W_n = x_1 + \cdots x_n | x_i \in w_i \forall i\)
\item
  \(x,y = W1 + Wn\) with \(xi + xn , y= y1 + yn xi,yi \in wi\)
\item
  then \(x+y = (xi + yi ) + \cdots \Leftrightarrow x + y \in W\)
\item
  The direct sum V1 plus in circle Vn is a space of f consitiing of all
  ntuples x1 to x2 where each Xi is from vi and the operations are
  corodinate wise)
\item
  x1 to Xn + (y1 to y\_n) = x+y1 + xn + yn
\item
  Let V be a vector space over a field F and let w1 to wn be subspaces
  of v

  \begin{itemize}
  \tightlist
  \item
    suppose that every vector x from b can be uniquely wriiten as x =
    x\_1 + X\_n where each xi is from wi
  \item
    Than v is isomorphic to the direct sum of w1 cirlce plus wn
  \item
    \textbf{Proof} An isomophism is a bijection which presevers
    perations
  \item
    define a mapping a from v to the direct sum by A\_x is a sum of n
    tuple x\_1 to x\_n where x is x\_1 to x\_n with x\_i an element from
    \(xi \in wi\)
  \item
    The image is this ntuple
  \item
    it is easy to check that a is one to one and a bijection and
    preseves operations and a of x plus a y = ax + ay
  \item
    What doe this strong condition
  \item
    +Proove that the following staments are equivalent.
  \end{itemize}

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi})}
  \tightlist
  \item
    every vector x from v can be uniquley written as x is x\_1 plus x\_n
    where each x\_i is from w\_i and
  \item
    v s the sum of all those subspaces the interesction of each wi with
    the sum of the rest of the subspaces = \{0\} for each i from 1 to n
  \item
    and w\_1 intersection w2 is = {[}0{]} \textbf{Proof} 1 implies 2 The
    sum part is obvious and follows from the fact that every vector x
    from v can be writtine the sum form. Now to see that the second part
    of 2 holds let \(x \in wi \cap \sum _{j \neq i }w_i\) write
    \(x as x = \sum[j \neq i] x_i x\in x \in w_i\) define \(x_i\) from
    wi by \(x_i = -x\) Than the sum x\_i for i from 1 to n is the zero
    vector which is minus x
    \(\sum i=1 \to n xi = \theta = \theta_ + \theta\) n times and so
    \(x = -xi = \theta\) \textbf{2 implies 1} That x can be writtin tin
    this from follows from the v is the sum of wi. \textbf{Uniquness}
    \(\underbrace{y_1 + x_1}{z_n} x_1 - y_1 = \theta\) show that z\_i =
    is the sum minus z\_j forall j neq i So zi is a vector from wi and
    wi is in the sumof wi
  \end{enumerate}
\end{itemize}

\hypertarget{rank-of-a-matirx}{%
\section{Rank of a matirx}\label{rank-of-a-matirx}}

Let a be an m by n matrix in the field n

Where the rows are vectors of Fn which is a subapce of fn and the
columns are vectors from fm which is a subsapce of A

The dimersion of the space is the row rank or column rank of the matrix

equivilantly the row rank of a is the number of thevectors in the
maximal linearly indeendent subsystem of vectors a1 to am The column
rank is identical

It can be easily checked that elementary row operations do change the
row the row rank. Elementary column operations do not change the column
rank

The reduced row echelon form of a produced by gauss elimination, and a
have the same row rank. The row rank of a is the number of none zero
rows in a row echelon from of a

The row rank and the column rank are equal? This is the main result and
this is the rank of the matrix

it suffices to show that the row rank does not exceed the column rank of
A (trivial taking the transpose) since the coloumns of c are linearly
indenpendent so there are only trivial solutions Consiquently row
echelon form of c has has k none zero rows. Therefore we must have k
linearly independent rows otherwise we would have a nontrivial solutions
pick k linearly independent rows of C Than the columns cj1 to cjk
corrisponding to bj1 to bjk are linearly independent Hence the column
rank of A is greater than or equal to K since the row and column rank is
equal they are called the rank of the matirx

Proove that a system of linear equations Ax =b hax a solution iff rank
of the extended matrix A\textbar{}b = rank A

\textbf{Proof} ax is b has a solution iff b belongs to coumn space of a
iff rank of ab is rank of a

Find a basis of the solution space of a system of homegenius equations

\hypertarget{linear-transformations}{%
\section{Linear Transformations}\label{linear-transformations}}

\begin{itemize}
\tightlist
\item
  Let v and w be vector spaces over the same field F
\item
  A mapping \(A:V \to W\) is a linear transformation if the following
  two axioms are satisfied
\item
  A(x+y) = A(x) + A(y) for all x,y in v
\item
  and saclar mulitplication is preseved
\item
  \(A: V \to V\) is a linear operator
\item
  \(V \to F\) is a linear functional
\item
  It follows from the axioms of a vector space that
\item
  \(A(\theta) = \theta\)

  \begin{itemize}
  \tightlist
  \item
    Proof
  \item
    \(A(\theta + \theta) = A(\theta) + A(\theta)\)
  \item
    \(a + a = a\)
  \item
    \(-a + a + a = -a + a\)
  \item
    \(a = \theta\)
  \end{itemize}
\item
  \textbf{ii}

  \begin{itemize}
  \tightlist
  \item
    \(A(-x) = -A(x)\)
  \item
    \(A(x) +(-A(x))\)
  \item
    \(A(\theta) = \theta\)
  \item
    \(A(-x)= A(x)\)
  \end{itemize}
\item
  \(A(\sum \alpha_i x_i) = \sum \alpha_i A(x_i)\)
\end{itemize}

Examples of linear tranformatinos

\begin{itemize}
\item
  The rotation of the plane about the origin through by some angle
  \(\phi\) countercloakwise
\item
  Proof is geometric
\item
\item
  Projection of the plane onto any line through the origin
\item
  Reflection
\item
  Any vector x
\item
  Also the reflection of the plane by a lnie through the originare
  linear operators
\item
  Transloation is not a linear operator
\item
  Let a be any m by n matrix over a field F and define A from fn to fm
  by A of x is A(x)
\item
  than A is a linaer transformations.
\item
  Infact any Matrix multiplication is a a linear tranformations
\end{itemize}

\hypertarget{differentiation-of-polynomials-is-a-linear-operations-d-fx-fx-to-fx-in-fx}{%
\subsection{\texorpdfstring{Differentiation of polynomials is a linear
operations:
\(D F[x] f(x) \to f'(x) \in F[x]\)}{Differentiation of polynomials is a linear operations: D F{[}x{]} f(x) \textbackslash{}to f'(x) \textbackslash{}in F{[}x{]}}}\label{differentiation-of-polynomials-is-a-linear-operations-d-fx-fx-to-fx-in-fx}}

\begin{itemize}
\tightlist
\item
  where \((\alpha_0 \alpha_2x ) = \alpha_1 + 2 \alpha_2 x\)
\item
  Intergration
\item
  \(C[a,b] f(x) \to \int_a^b f(x)dx \in \mathbb{R}\)
\item
  There are many anti derivaties of a given funciton (artbitrary
  constants)
\end{itemize}

\hypertarget{linear-operrators-ii}{%
\subsection{Linear operrators II}\label{linear-operrators-ii}}

\begin{itemize}
\item
  For every linear transformation A from V to W
\item
  The kernal is the set of a vectors mapping to \(\theta\)
\item
  The image of A Is the set of a ys mapped to
\item
  Both the kernal and the image are subspaces of V and the image of A is
  a subspace of W To see for example that the kernal is a subspace
\item
  \(x,y \in ker A A(x) = \theta a(y) = \theta\)
\end{itemize}

\textbf{Theroem}

Assume that V is finit dimensional

Then the dimension of the kernal of A + the dimension of the image of A
is the dimension of V Proof Pick a basis a1 to am in the kernal and
extend it to a basis \(a1 , an, b1, bk \in V\) And so we claim that
\(A (b1) \to A9(bK)\) is a basis of the image of A.

\begin{itemize}
\item
  To see that the span of \(<A(b1) \dots A(bn)> = image A let y \in A\)
\item
  Then \(x \in V\) s.i \(A(x)=y\)
\item
  Write x as \(\alpha_1 a1 +\)
\item
  Then \(y = A(x) =A(alpha a a1 + ... + \beta_1 b1 +...)\)
\item
  \(= 0 + \beta1 + beta(A)\)
\item
  To see that \(A(b1) ... A(bk)\) are linearly independent
\item
  Consider an arbitrary linear combination of the As
\item
  As a is a linear combinaion take A of an arbitary linaer combinations
  of b
\item
  All bs are memebers of the kernal of A
\item
  So the linear combination of bs can be expressed in the basis of ker A
  which are as
\item
  so alpha \(a + .. - \beta 1 b1 = \theta\)
\item
  impleis all alphas and betas must be zeros
\item
  The alphas form an image of the keranl and the bs form an image of the
  kernal together they form a basis of the system
\item
  Then the dimansion of it solution space is n-rank(a) so
\end{itemize}

\begin{quote}
Proof Define A from \(F^n \to F^m\) \(A(x) = A(x)\) Then the kernal of
this linear tranformation is the solution space of our system And the
image of a is the column space of our matrix Which is the rank of the
matrix Then apply the theroem Suppose that the rank o
\end{quote}

\hypertarget{test-the-chapter-vector-spaces-not-includeding-linear-tranformations}{%
\section{Test The chapter vector spaces not includeding linear
tranformations}\label{test-the-chapter-vector-spaces-not-includeding-linear-tranformations}}

\begin{itemize}
\tightlist
\item
  Typical exersizes

  \begin{itemize}
  \tightlist
  \item
    Supppose you have some vectors in a vector space check if the some
    vectors form a basis of that space and find the coordinates of that
    vector
  \item
    Perform gauss elemination and if you get the identity matix it is a
    bisis and the cordinates of another vector is
  \item
    \textbf{The transition matirx is from S to S'} !!!!!!!!

    \begin{itemize}
    \tightlist
    \item
      S\textbar{}S' and perform gauss elimination to get E\textbar{}T
    \item
      The cordinate of x is the new basis {[}x{]}\_s = T\{x\}\_s'
    \end{itemize}
  \item
    Proove simpler statment not two system lemma
  \end{itemize}
\end{itemize}

\end{document}
